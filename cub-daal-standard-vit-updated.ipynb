{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5140550,"sourceType":"datasetVersion","datasetId":2534241},{"sourceId":386298,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":318560,"modelId":339138}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Data prepration","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:49:30.624353Z","iopub.execute_input":"2025-05-11T11:49:30.624501Z","iopub.status.idle":"2025-05-11T11:49:31.104298Z","shell.execute_reply.started":"2025-05-11T11:49:30.624486Z","shell.execute_reply":"2025-05-11T11:49:31.103488Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"bouding_boxes_image_path = \"/kaggle/input/cub2002011/CUB_200_2011/bounding_boxes.txt\" #1 60.0 27.0 325.0 304.0\nclasses_image_path = \"/kaggle/input/cub2002011/CUB_200_2011/image_class_labels.txt\" # 2 002.Laysan_Albatross\nimage_path_file = \"/kaggle/input/cub2002011/CUB_200_2011/images.txt\" #1 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\ntrain_test_file = \"/kaggle/input/cub2002011/CUB_200_2011/train_test_split.txt\" #1 0\n\nfile_paths = [\n    image_path_file,\n    train_test_file,\n    bouding_boxes_image_path,\n    classes_image_path,\n]\n# Open all files at once\nfiles = [open(file_path, 'r') for file_path in file_paths]\n# # Initialize an empty list to store the line-by-line extracted info\ndataset = {}\n# # Loop through the files line by line simultaneously\n# max_class_names = 20\n\n#only select 10 for each class now\ntry:\n    while True:\n        # Read one line from each file\n        lines = [(file.name, file.readline().strip()) for file in files]\n#         print(len(lines))\n        # If any file reaches the end, break the loop\n        if any(line == '' for _, line in lines):\n            break\n#         is_training_set = lines[0][1].split(\" \")[0] == '1'\n        class_name = lines[3][1].split(\" \")[1]\n        dataset[lines[0][1].split(\" \")[1]] = {\n            \"is_training\": True if lines[1][1].split(\" \")[1] == '1' else False,\n            \"bounding_boxes\": lines[2][1].split(\" \")[1:],\n            \"class_name\": class_name\n        }\n\n        \nfinally:\n    # Make sure to close all files after reading\n    for file in files:\n        file.close()\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:49:41.048714Z","iopub.execute_input":"2025-05-11T11:49:41.049186Z","iopub.status.idle":"2025-05-11T11:49:41.125436Z","shell.execute_reply.started":"2025-05-11T11:49:41.049151Z","shell.execute_reply":"2025-05-11T11:49:41.124705Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"### count the datasets\ntraining_dataset_count = 0\ntesting_dataset_count = 0\nclass_counts = {}\nmax_count = 0\nmin_count = 0\nfor key,value in dataset.items():\n    if value[\"is_training\"] == True:\n        training_dataset_count +=1\n    else:\n        testing_dataset_count +=1\n    class_name = value[\"class_name\"]\n    if class_name in class_counts.keys():\n        class_counts[class_name] += 1\n    else:\n        class_counts[class_name] = 0\nmax_class = max(class_counts, key=class_counts.get)\nmin_class = min(class_counts, key=class_counts.get)\nprint(\"Training count={0}\".format(training_dataset_count))\nprint(\"Testing count={0}\".format(testing_dataset_count))\n### create embeddings for cub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:49:45.563927Z","iopub.execute_input":"2025-05-11T11:49:45.564608Z","iopub.status.idle":"2025-05-11T11:49:45.575241Z","shell.execute_reply.started":"2025-05-11T11:49:45.564584Z","shell.execute_reply":"2025-05-11T11:49:45.574597Z"}},"outputs":[{"name":"stdout","text":"Training count=5994\nTesting count=5794\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def crop_image_with_bounding_box(image_cv, bounding_boxes):\n    x, y, w, h = bounding_boxes\n    # Crop the image using NumPy slicing\n    cropped_image = image_cv[y:y+h, x:x+w]\n    return cropped_image\n\ndef read_image_return_cropped(image_path, bounding_boxes, target_size=(224, 224)):\n    # Step 1: Load the image using OpenCV\n    image_cv = cv2.imread(image_path)\n\n    # Step 2: Convert BGR to RGB (OpenCV loads images in BGR by default)\n    image_cv_rgb = cv2.cvtColor(image_cv, cv2.COLOR_BGR2RGB)\n\n    # Step 3: Crop the image using the bounding box\n    cropped_image_cv = crop_image_with_bounding_box(image_cv_rgb, bounding_boxes)\n\n    # Step 4: Resize the cropped image to the target size using cv2\n    cropped_image_resized = cv2.resize(cropped_image_cv, target_size)\n\n    # Step 5: Check if the image is grayscale and convert to RGB if necessary\n    if len(cropped_image_resized.shape) == 2 or cropped_image_resized.shape[2] == 1:\n        cropped_image_resized = cv2.cvtColor(cropped_image_resized, cv2.COLOR_GRAY2RGB)\n\n    # Step 6: Preprocess the image for VGG16 model (normalize pixel values)\n    return cropped_image_resized","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:49:47.899974Z","iopub.execute_input":"2025-05-11T11:49:47.900352Z","iopub.status.idle":"2025-05-11T11:49:47.912796Z","shell.execute_reply.started":"2025-05-11T11:49:47.900319Z","shell.execute_reply":"2025-05-11T11:49:47.911734Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"images_train = []\nlabels_train = []\nimages_test = []\nlabels_test = []\nmain_path = \"/kaggle/input/cub2002011/CUB_200_2011/images/\"\ncount = 0\nfor key,value in dataset.items():\n    (x,y,w,h) = value['bounding_boxes']\n    is_training = value[\"is_training\"]\n    class_label = value[\"class_name\"]\n    image_path = os.path.join(main_path, key)\n    cropped_image = read_image_return_cropped(image_path, (int(float(x)), int(float(y)), int(float(w)), int(float(h))))\n    if is_training: \n        images_train.append(cropped_image)\n        labels_train.append(class_label)\n    else:\n        images_test.append(cropped_image)\n        labels_test.append(class_label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:49:49.858519Z","iopub.execute_input":"2025-05-11T11:49:49.859203Z","iopub.status.idle":"2025-05-11T11:51:48.533446Z","shell.execute_reply.started":"2025-05-11T11:49:49.859171Z","shell.execute_reply":"2025-05-11T11:51:48.532700Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"X_train = np.array(images_train)\ny_train = np.array(labels_train)\nX_temp = np.array(images_test)\ny_temp = np.array(labels_test)\n\n# Verify the shapes\nprint(f'Images shape: {X_train.shape}')  # (num_images, 224, 224, 3)\nprint(f'Labels shape: {y_train.shape}')  # (num_images,)\nprint(f'Images shape: {X_temp.shape}')  # (num_images, 224, 224, 3)\nprint(f'Labels shape: {y_temp.shape}')  # (num_images,)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:52:06.110901Z","iopub.execute_input":"2025-05-11T11:52:06.111170Z","iopub.status.idle":"2025-05-11T11:52:06.642603Z","shell.execute_reply.started":"2025-05-11T11:52:06.111147Z","shell.execute_reply":"2025-05-11T11:52:06.641823Z"}},"outputs":[{"name":"stdout","text":"Images shape: (5994, 224, 224, 3)\nLabels shape: (5994,)\nImages shape: (5794, 224, 224, 3)\nLabels shape: (5794,)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Data preprocessing","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nimport numpy as np\n\n# ViT expects images normalized to [-1, 1]\ndef vit_preprocess(images):\n    return (np.array(images).astype(np.float32) / 127.5) - 1.0  # → [-1, 1]\n\n# One-hot encode labels\none_hot_encoder = OneHotEncoder(sparse=False)\ny_train = one_hot_encoder.fit_transform(np.array(labels_train).reshape(-1, 1))\ny_temp = one_hot_encoder.transform(np.array(labels_test).reshape(-1, 1))\n\n# Preprocess image data for ViT\nX_train = vit_preprocess(images_train)\nX_temp = vit_preprocess(images_test)\n\n# Split test portion into validation and test sets\nX_test, X_val, y_test, y_val = train_test_split(\n    X_temp, y_temp,\n    test_size=0.2,\n    random_state=42\n)\n\n# Print shapes to verify\nprint(f\"Train set:      {X_train.shape}, {y_train.shape}\")\nprint(f\"Test set:       {X_test.shape},  {y_test.shape}\")\nprint(f\"Validation set: {X_val.shape},  {y_val.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:52:16.590975Z","iopub.execute_input":"2025-05-11T11:52:16.591816Z","iopub.status.idle":"2025-05-11T11:52:22.685294Z","shell.execute_reply.started":"2025-05-11T11:52:16.591788Z","shell.execute_reply":"2025-05-11T11:52:22.684659Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train set:      (5994, 224, 224, 3), (5994, 200)\nTest set:       (4635, 224, 224, 3),  (4635, 200)\nValidation set: (1159, 224, 224, 3),  (1159, 200)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"!pip install transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:52:26.369681Z","iopub.execute_input":"2025-05-11T11:52:26.370034Z","iopub.status.idle":"2025-05-11T11:52:30.314894Z","shell.execute_reply.started":"2025-05-11T11:52:26.370009Z","shell.execute_reply":"2025-05-11T11:52:30.313925Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"print(X_train.shape)  # should be (batch_size, 224, 224, 3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:52:31.446578Z","iopub.execute_input":"2025-05-11T11:52:31.447158Z","iopub.status.idle":"2025-05-11T11:52:31.451496Z","shell.execute_reply.started":"2025-05-11T11:52:31.447129Z","shell.execute_reply":"2025-05-11T11:52:31.450880Z"}},"outputs":[{"name":"stdout","text":"(5994, 224, 224, 3)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models, regularizers\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nclass CenterLossLayer(tf.keras.layers.Layer):\n    def __init__(self, num_classes, embedding_dim, margin=1.5, alpha=0.001, **kwargs):\n        super(CenterLossLayer, self).__init__(**kwargs)\n        self.num_classes = num_classes\n        self.embedding_dim = embedding_dim\n        self.margin = tf.cast(margin, tf.float32)\n        self.alpha = alpha  # EMA smoothing factor\n        self.distance = 0.1  # The length between P1 and P2\n\n        # Initialize center_p1 randomly using a normal distribution\n        self.centers_P1 = self.add_weight(name='centers_P1',\n                                          shape=(num_classes, embedding_dim),\n                                          initializer='random_normal',\n                                          trainable=False,\n                                          dtype=tf.float32)\n\n        # Create center_p2 without initialization\n        self.centers_P2 = self.add_weight(name='centers_P2',\n                                          shape=(num_classes, embedding_dim),\n                                          initializer='zeros',\n                                          trainable=False,\n                                          dtype=tf.float32)\n\n    def build(self, input_shape):\n        # Generate a random unit vector direction for center_p2\n        random_direction = tf.random.normal((self.num_classes, self.embedding_dim))\n        unit_vector = random_direction / tf.norm(random_direction, axis=1, keepdims=True)  # Normalize\n\n        # Assign center_p2 to be 'distance' units away from center_p1\n        center_p2_value = self.distance * unit_vector\n        self.centers_P2.assign(center_p2_value)\n\n        super(CenterLossLayer, self).build(input_shape)\n    \n    def call(self, inputs):\n        embeddings, labels = inputs\n\n        # Ensure embeddings and labels are float32\n        embeddings = tf.cast(embeddings, tf.float32)\n        labels = tf.argmax(labels, axis=-1, output_type=tf.int32)\n\n        # Step 1: Compute the midpoint for each class (mean of embeddings for each class)\n        batch_midpoint = tf.math.unsorted_segment_mean(embeddings, labels, num_segments=self.num_classes)\n\n        # Step 2: Calculate the variance for each class\n        squared_diff = tf.square(embeddings - tf.gather(batch_midpoint, labels))\n        batch_variance = tf.math.unsorted_segment_mean(squared_diff, labels, num_segments=self.num_classes)\n\n        # Step 3: Compute the standard deviation (sqrt of variance)\n        batch_stddev = tf.sqrt(batch_variance)\n\n        # Step 4: Position centers_P1 and centers_P2 around the midpoint\n        # Center_P1 closer to the midpoint, Center_P2 further from the midpoint\n        batch_centers_P1 = batch_midpoint - 0.5 * batch_stddev  # Center_P1 inside dense region\n        batch_centers_P2 = batch_midpoint + 0.5 * batch_stddev  # Center_P2 outside dense region\n\n        # Gather the centers corresponding to the labels\n        batch_centers_P1_gathered = tf.gather(batch_centers_P1, labels)\n        batch_centers_P2_gathered = tf.gather(batch_centers_P2, labels)\n\n        # Step 5: Update centers using EMA (Exponential Moving Average)\n        center_updates_P1 = tf.scatter_nd(tf.expand_dims(labels, 1),\n                                          batch_centers_P1_gathered,\n                                          shape=tf.shape(self.centers_P1))\n        center_updates_P2 = tf.scatter_nd(tf.expand_dims(labels, 1),\n                                          batch_centers_P2_gathered,\n                                          shape=tf.shape(self.centers_P2))\n\n        # EMA update for centers_P1 and centers_P2\n        new_centers_P1 = self.centers_P1 * (1 - self.alpha) + center_updates_P1 * self.alpha\n        new_centers_P2 = self.centers_P2 * (1 - self.alpha) + center_updates_P2 * self.alpha\n\n        # Assign updated centers\n        self.centers_P1.assign(new_centers_P1)\n        self.centers_P2.assign(new_centers_P2)\n\n        # Step 6: Compute distances to all class segments for each embedding\n        distances = self.compute_distance_to_segment_all_classes(embeddings)\n\n        # Step 7: Get the correct distances by indexing with labels\n        correct_distances = tf.gather_nd(distances, tf.expand_dims(labels, axis=-1), batch_dims=1)\n\n        # Step 8: Mask out correct class distances and find the minimum incorrect distance\n        mask = tf.one_hot(labels, depth=self.num_classes, on_value=False, off_value=True)\n        masked_distances = tf.where(mask, distances, tf.fill(tf.shape(distances), float('inf')))\n        min_incorrect_distances = tf.reduce_min(masked_distances, axis=1)\n\n        # Step 9: Compute the loss\n        incorrect_loss = tf.maximum(0.0, self.margin - min_incorrect_distances)\n        center_loss = tf.reduce_mean(tf.square(correct_distances))\n\n        return center_loss + tf.reduce_mean(incorrect_loss)\n\n\n    def compute_distance_to_segment_all_classes(self, embeddings):\n        \"\"\"\n        Compute the Euclidean distance from each embedding to the nearest point on the line segment\n        defined by P1 and P2 for each class.\n        \"\"\"\n        # Get P1 and P2 for all classes\n        P1 = self.centers_P1\n        P2 = self.centers_P2\n\n        # Vector from P1 to P2 for all classes\n        P1_P2 = P2 - P1\n\n        # Expand dims for broadcasting\n        P1 = tf.expand_dims(P1, axis=0)\n        P2 = tf.expand_dims(P2, axis=0)\n        P1_P2 = tf.expand_dims(P1_P2, axis=0)\n        embeddings = tf.expand_dims(embeddings, axis=1)\n\n        # Vector from P1 to the embeddings\n        P1_emb = embeddings - P1\n\n        # Project embeddings onto the line segment\n        proj = tf.reduce_sum(P1_emb * P1_P2, axis=2, keepdims=True) / tf.maximum(tf.reduce_sum(P1_P2 ** 2, axis=2, keepdims=True), 1e-8)\n\n        # Clamp projection to the range [0, 1] to restrict to the segment\n        proj_clamped = tf.clip_by_value(proj, 0.0, 1.0)\n\n        # Compute the nearest point on the line segment\n        nearest_point = P1 + proj_clamped * P1_P2\n\n        # Compute the Euclidean distance to the nearest point on the segment\n        distances = tf.norm(embeddings - nearest_point, axis=2)\n\n        return distances\n        \nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom transformers import TFViTModel\n\nclass ViTCLSLayer(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.vit = TFViTModel.from_pretrained(\"WinKawaks/vit-small-patch16-224\")\n        self.vit.trainable = False\n\n    def call(self, inputs):\n        # Convert NHWC to NCHW for ViT (if required)\n        inputs_nchw = tf.transpose(inputs, perm=[0, 3, 1, 2])\n        outputs = self.vit(pixel_values=inputs_nchw, training=False)\n        return outputs.last_hidden_state[:, 0, :]\n\n\ndef build_vit_center_loss(input_shape, num_classes, embedding_dim, dropout_rate, weight_decay):\n    # Inputs\n    inputs = tf.keras.Input(shape=input_shape, name='input')\n    labels_input = tf.keras.Input(shape=(num_classes,), name='labels_input')  # assuming one-hot labels\n\n    # Normalize to [-1, 1]\n    # x = tf.keras.layers.Rescaling(scale=1./127.5, offset=-1)(inputs)\n    x = inputs\n\n    # ViT feature extractor (CLS token)\n    x = ViTCLSLayer(name='vit_cls_token')(x)\n\n    # Optional projection to embedding space\n    if embedding_dim != 768:\n        x = layers.Dense(embedding_dim, activation='swish')(x)\n\n    # MLP head with regularization and dropout\n    x = layers.Dense(1024, activation='swish',\n                     kernel_regularizer=regularizers.l2(weight_decay),\n                     bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dropout(dropout_rate)(x)\n\n    x = layers.Dense(512, activation='swish',\n                     kernel_regularizer=regularizers.l2(weight_decay),\n                     bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dropout(dropout_rate)(x)\n\n    x = layers.Dense(512, activation='swish',\n                     kernel_regularizer=regularizers.l2(weight_decay),\n                     bias_regularizer=regularizers.l2(0.01))(x)\n    x = layers.Dropout(dropout_rate)(x)\n\n    x = layers.Dense(1024, activation='swish',\n                     kernel_regularizer=regularizers.l2(weight_decay),\n                     bias_regularizer=regularizers.l2(0.01))(x)\n\n    # Final projection to embedding space (again)\n    x = layers.Dense(embedding_dim, activation='swish')(x)\n\n    # Embedding model\n    embedding_model = models.Model(inputs=inputs, outputs=x, name='vit_embedding_model')\n    embedding = embedding_model(inputs)\n\n    # Classification head\n    logits = layers.Dense(num_classes, activation='softmax', name='classification_layer')(embedding)\n\n    # Center loss branch\n    center_loss_output = CenterLossLayer(num_classes=num_classes, embedding_dim=embedding_dim)([embedding, labels_input])\n\n    # Full model\n    full_model = models.Model(\n        inputs=[inputs, labels_input],\n        outputs=[logits, center_loss_output],\n        name='full_model_vit'\n    )\n\n    return embedding_model, full_model\n\n\n\n\ndef train_and_evaluate(model, train_generator, val_generator, steps_per_epoch, validation_steps, epochs, center_loss_weight, learning_rate):\n    optimizer = tf.keras.optimizers.RMSprop(learning_rate)\n\n    history = {\n        \"train_loss\": [],\n        \"train_class_loss\": [],\n        \"train_center_loss\": [],\n        \"train_acc\": [],\n        \"val_class_loss\": [],\n        \"val_center_loss\": [],\n        \"val_acc\": []\n    }\n\n    @tf.function\n    def train_step(inputs, labels):\n        with tf.GradientTape() as tape:\n            logits, center_loss = model([inputs, labels], training=True)\n            classification_loss = tf.keras.losses.CategoricalCrossentropy()(labels, logits)\n            total_loss = classification_loss + center_loss_weight * center_loss\n\n        gradients = tape.gradient(total_loss, model.trainable_variables)\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n        predictions = tf.argmax(logits, axis=-1)\n        labels_true = tf.argmax(labels, axis=-1)\n        train_acc = tf.reduce_mean(tf.cast(tf.equal(predictions, labels_true), tf.float32))\n\n        return total_loss, classification_loss, center_loss, train_acc\n\n    @tf.function\n    def eval_step(inputs, labels):\n        logits, center_loss = model([inputs, labels], training=False)\n        classification_loss = tf.keras.losses.CategoricalCrossentropy()(labels, logits)\n\n        predictions = tf.argmax(logits, axis=-1)\n        labels_true = tf.argmax(labels, axis=-1)\n        accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, labels_true), tf.float32))\n\n        return classification_loss, center_loss, accuracy\n\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch+1}/{epochs}\")\n\n        # Training loop\n        epoch_loss, epoch_class_loss, epoch_center_loss, epoch_acc = 0, 0, 0, 0\n        for step in range(steps_per_epoch):\n            inputs_batch, labels_batch = next(train_generator)\n            loss, class_loss, center_loss, acc = train_step(inputs_batch, labels_batch)\n            epoch_loss += loss\n            epoch_class_loss += class_loss\n            epoch_center_loss += center_loss\n            epoch_acc += acc\n\n        epoch_loss /= steps_per_epoch\n        epoch_class_loss /= steps_per_epoch\n        epoch_center_loss /= steps_per_epoch\n        epoch_acc /= steps_per_epoch\n\n        print(f\"Train Loss: {epoch_loss:.4f}, Class Loss: {epoch_class_loss:.4f}, Center Loss: {epoch_center_loss:.4f}, Acc: {epoch_acc:.4f}\")\n\n        history[\"train_loss\"].append(epoch_loss)\n        history[\"train_class_loss\"].append(epoch_class_loss)\n        history[\"train_center_loss\"].append(epoch_center_loss)\n        history[\"train_acc\"].append(epoch_acc)\n\n        # Validation loop\n        val_class_loss, val_center_loss, val_acc = 0, 0, 0\n        for step in range(validation_steps):\n            inputs_batch, labels_batch = next(val_generator)\n            class_loss, center_loss, acc = eval_step(inputs_batch, labels_batch)\n            val_class_loss += class_loss\n            val_center_loss += center_loss\n            val_acc += acc\n\n        val_class_loss /= validation_steps\n        val_center_loss /= validation_steps\n        val_acc /= validation_steps\n\n        print(f\"Val Class Loss: {val_class_loss:.4f}, Val Center Loss: {val_center_loss:.4f}, Val Acc: {val_acc:.4f}\")\n\n        history[\"val_class_loss\"].append(val_class_loss)\n        history[\"val_center_loss\"].append(val_center_loss)\n        history[\"val_acc\"].append(val_acc)\n\n    return history\n\n# Initialize ImageDataGenerator with augmentation options (without rescaling)\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,           # Randomly rotate images by 20 degrees\n    width_shift_range=0.2,       # Randomly shift images horizontally\n    height_shift_range=0.2,      # Randomly shift images vertically\n    shear_range=0.2,             # Shear transformation\n    zoom_range=0.2,              # Zoom in/out\n    horizontal_flip=True,        # Random horizontal flipping\n    fill_mode='nearest'          # Filling pixels after transformations\n)\n\n# Example usage with specified values\ninput_shape = (224, 224, 3)        # Input shape for images (224x224 RGB)\nnum_classes = y_train.shape[1]                  # Number of classes in the dataset\nembedding_dim = 1000              # Dimensionality of the embedding space\ndropout_rate = 0.2               # Dropout rate for regularization\nweight_decay = 0.05 #0.005            # L2 regularization weight\ncenter_loss_weight = 0.01 #0.0001          # Weight for center loss\nlearning_rate = 1e-4               # Learning rate for the optimizer\nbatch_size = 64                    # Batch size for training\nepochs = 40                      # Number of epochs to train\n\nval_datagen = ImageDataGenerator()  # No additional augmentations for validation\n\n# Load and augment training data\ntrain_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n\n# Load validation data\nval_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)\n\nsteps_per_epoch = len(X_train) // batch_size\nvalidation_steps = len(X_val)  // batch_size\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:57:25.479969Z","iopub.execute_input":"2025-05-11T11:57:25.480680Z","iopub.status.idle":"2025-05-11T11:57:25.509436Z","shell.execute_reply.started":"2025-05-11T11:57:25.480655Z","shell.execute_reply":"2025-05-11T11:57:25.508707Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Build the model using VGG19 and center loss\nembedding_model, full_model = build_vit_center_loss(input_shape, num_classes, embedding_dim, dropout_rate, weight_decay)\n# Train the model using data generators\nhistory = train_and_evaluate(full_model, train_generator, val_generator, steps_per_epoch, validation_steps, epochs, center_loss_weight, learning_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:57:31.259318Z","iopub.execute_input":"2025-05-11T11:57:31.259568Z","iopub.status.idle":"2025-05-11T12:48:26.738318Z","shell.execute_reply.started":"2025-05-11T11:57:31.259550Z","shell.execute_reply":"2025-05-11T12:48:26.737284Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c437ba595f142c1ae542314209c7f49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/88.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80d1323d4bf043af9a1efed05c418dfc"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFViTModel: ['classifier.bias', 'classifier.weight']\n- This IS expected if you are initializing TFViTModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFViTModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFViTModel were not initialized from the PyTorch model and are newly initialized: ['vit.pooler.dense.weight', 'vit.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/40\nTrain Loss: 5.1037, Class Loss: 5.0160, Center Loss: 8.7742, Acc: 0.1742\nVal Class Loss: 4.3008, Val Center Loss: 16.7388, Val Acc: 0.4766\nEpoch 2/40\nTrain Loss: 4.0659, Class Loss: 3.5208, Center Loss: 54.5073, Acc: 0.4497\nVal Class Loss: 2.5190, Val Center Loss: 56.5722, Val Acc: 0.6395\nEpoch 3/40\nTrain Loss: 3.1405, Class Loss: 2.3567, Center Loss: 78.3792, Acc: 0.6094\nVal Class Loss: 1.8530, Val Center Loss: 58.5822, Val Acc: 0.7325\nEpoch 4/40\nTrain Loss: 2.5732, Class Loss: 1.7831, Center Loss: 79.0147, Acc: 0.7049\nVal Class Loss: 1.3677, Val Center Loss: 61.0172, Val Acc: 0.7777\nEpoch 5/40\nTrain Loss: 2.1933, Class Loss: 1.4490, Center Loss: 74.4229, Acc: 0.7570\nVal Class Loss: 1.1664, Val Center Loss: 56.3721, Val Acc: 0.8053\nEpoch 6/40\nTrain Loss: 1.9122, Class Loss: 1.2171, Center Loss: 69.5045, Acc: 0.7983\nVal Class Loss: 0.9969, Val Center Loss: 49.5370, Val Acc: 0.8297\nEpoch 7/40\nTrain Loss: 1.7101, Class Loss: 1.0683, Center Loss: 64.1839, Acc: 0.8138\nVal Class Loss: 0.8598, Val Center Loss: 48.9515, Val Acc: 0.8575\nEpoch 8/40\nTrain Loss: 1.5246, Class Loss: 0.9303, Center Loss: 59.4353, Acc: 0.8313\nVal Class Loss: 0.8275, Val Center Loss: 44.2037, Val Acc: 0.8359\nEpoch 9/40\nTrain Loss: 1.3823, Class Loss: 0.8293, Center Loss: 55.2995, Acc: 0.8498\nVal Class Loss: 0.7835, Val Center Loss: 39.4290, Val Acc: 0.8533\nEpoch 10/40\nTrain Loss: 1.2590, Class Loss: 0.7404, Center Loss: 51.8599, Acc: 0.8733\nVal Class Loss: 0.6743, Val Center Loss: 39.0078, Val Acc: 0.8653\nEpoch 11/40\nTrain Loss: 1.1637, Class Loss: 0.6825, Center Loss: 48.1170, Acc: 0.8720\nVal Class Loss: 0.6374, Val Center Loss: 36.3106, Val Acc: 0.8433\nEpoch 12/40\nTrain Loss: 1.0686, Class Loss: 0.6135, Center Loss: 45.5122, Acc: 0.8850\nVal Class Loss: 0.6167, Val Center Loss: 33.6963, Val Acc: 0.8714\nEpoch 13/40\nTrain Loss: 1.0105, Class Loss: 0.5839, Center Loss: 42.6544, Acc: 0.8942\nVal Class Loss: 0.5655, Val Center Loss: 33.8304, Val Acc: 0.8724\nEpoch 14/40\nTrain Loss: 0.9344, Class Loss: 0.5273, Center Loss: 40.7024, Acc: 0.9001\nVal Class Loss: 0.5714, Val Center Loss: 31.4984, Val Acc: 0.8731\nEpoch 15/40\nTrain Loss: 0.8753, Class Loss: 0.4898, Center Loss: 38.5493, Acc: 0.9114\nVal Class Loss: 0.5299, Val Center Loss: 29.8251, Val Acc: 0.8593\nEpoch 16/40\nTrain Loss: 0.8204, Class Loss: 0.4524, Center Loss: 36.8066, Acc: 0.9160\nVal Class Loss: 0.5329, Val Center Loss: 28.8223, Val Acc: 0.8740\nEpoch 17/40\nTrain Loss: 0.7798, Class Loss: 0.4296, Center Loss: 35.0283, Acc: 0.9204\nVal Class Loss: 0.4888, Val Center Loss: 27.4422, Val Acc: 0.8837\nEpoch 18/40\nTrain Loss: 0.7284, Class Loss: 0.3912, Center Loss: 33.7187, Acc: 0.9305\nVal Class Loss: 0.4739, Val Center Loss: 26.7036, Val Acc: 0.8889\nEpoch 19/40\nTrain Loss: 0.7004, Class Loss: 0.3762, Center Loss: 32.4194, Acc: 0.9323\nVal Class Loss: 0.5309, Val Center Loss: 25.2038, Val Acc: 0.8704\nEpoch 20/40\nTrain Loss: 0.6559, Class Loss: 0.3451, Center Loss: 31.0810, Acc: 0.9360\nVal Class Loss: 0.4719, Val Center Loss: 24.0972, Val Acc: 0.8872\nEpoch 21/40\nTrain Loss: 0.6151, Class Loss: 0.3154, Center Loss: 29.9659, Acc: 0.9431\nVal Class Loss: 0.4469, Val Center Loss: 23.8005, Val Acc: 0.8845\nEpoch 22/40\nTrain Loss: 0.5960, Class Loss: 0.3078, Center Loss: 28.8254, Acc: 0.9452\nVal Class Loss: 0.4575, Val Center Loss: 22.8245, Val Acc: 0.8880\nEpoch 23/40\nTrain Loss: 0.5682, Class Loss: 0.2878, Center Loss: 28.0351, Acc: 0.9502\nVal Class Loss: 0.4272, Val Center Loss: 22.1718, Val Acc: 0.8984\nEpoch 24/40\nTrain Loss: 0.5413, Class Loss: 0.2704, Center Loss: 27.0857, Acc: 0.9530\nVal Class Loss: 0.4911, Val Center Loss: 21.1958, Val Acc: 0.8713\nEpoch 25/40\nTrain Loss: 0.5183, Class Loss: 0.2559, Center Loss: 26.2403, Acc: 0.9560\nVal Class Loss: 0.4237, Val Center Loss: 20.8925, Val Acc: 0.8880\nEpoch 26/40\nTrain Loss: 0.4891, Class Loss: 0.2341, Center Loss: 25.4951, Acc: 0.9638\nVal Class Loss: 0.4549, Val Center Loss: 20.6965, Val Acc: 0.8704\nEpoch 27/40\nTrain Loss: 0.4762, Class Loss: 0.2284, Center Loss: 24.7758, Acc: 0.9628\nVal Class Loss: 0.4506, Val Center Loss: 20.0949, Val Acc: 0.8906\nEpoch 28/40\nTrain Loss: 0.4590, Class Loss: 0.2185, Center Loss: 24.0524, Acc: 0.9643\nVal Class Loss: 0.4016, Val Center Loss: 19.8073, Val Acc: 0.9010\nEpoch 29/40\nTrain Loss: 0.4408, Class Loss: 0.2060, Center Loss: 23.4804, Acc: 0.9663\nVal Class Loss: 0.4562, Val Center Loss: 18.6672, Val Acc: 0.8775\nEpoch 30/40\nTrain Loss: 0.4158, Class Loss: 0.1874, Center Loss: 22.8422, Acc: 0.9719\nVal Class Loss: 0.4273, Val Center Loss: 17.6457, Val Acc: 0.8879\nEpoch 31/40\nTrain Loss: 0.4086, Class Loss: 0.1859, Center Loss: 22.2651, Acc: 0.9724\nVal Class Loss: 0.4804, Val Center Loss: 18.3893, Val Acc: 0.8792\nEpoch 32/40\nTrain Loss: 0.3966, Class Loss: 0.1794, Center Loss: 21.7173, Acc: 0.9735\nVal Class Loss: 0.4101, Val Center Loss: 17.9376, Val Acc: 0.8834\nEpoch 33/40\nTrain Loss: 0.3784, Class Loss: 0.1650, Center Loss: 21.3367, Acc: 0.9758\nVal Class Loss: 0.4451, Val Center Loss: 17.0299, Val Acc: 0.8759\nEpoch 34/40\nTrain Loss: 0.3686, Class Loss: 0.1616, Center Loss: 20.6999, Acc: 0.9775\nVal Class Loss: 0.4527, Val Center Loss: 16.8404, Val Acc: 0.8852\nEpoch 35/40\nTrain Loss: 0.3537, Class Loss: 0.1514, Center Loss: 20.2276, Acc: 0.9782\nVal Class Loss: 0.4091, Val Center Loss: 15.7111, Val Acc: 0.8941\nEpoch 36/40\nTrain Loss: 0.3481, Class Loss: 0.1497, Center Loss: 19.8416, Acc: 0.9787\nVal Class Loss: 0.4791, Val Center Loss: 16.2528, Val Acc: 0.8932\nEpoch 37/40\nTrain Loss: 0.3286, Class Loss: 0.1356, Center Loss: 19.2998, Acc: 0.9835\nVal Class Loss: 0.4689, Val Center Loss: 15.2265, Val Acc: 0.8862\nEpoch 38/40\nTrain Loss: 0.3154, Class Loss: 0.1267, Center Loss: 18.8741, Acc: 0.9834\nVal Class Loss: 0.4184, Val Center Loss: 15.2004, Val Acc: 0.8880\nEpoch 39/40\nTrain Loss: 0.3115, Class Loss: 0.1277, Center Loss: 18.3774, Acc: 0.9836\nVal Class Loss: 0.4473, Val Center Loss: 15.0075, Val Acc: 0.8811\nEpoch 40/40\nTrain Loss: 0.2971, Class Loss: 0.1160, Center Loss: 18.1144, Acc: 0.9866\nVal Class Loss: 0.4489, Val Center Loss: 14.7153, Val Acc: 0.8844\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## Modal evaluation","metadata":{}},{"cell_type":"code","source":"# Save the history to a .pkl file\nimport pickle\nwith open('/kaggle/working/cub_history_standard_vit.pkl', 'wb') as file:\n    pickle.dump(history, file)\n\n# Save the embedding model\nembedding_model.save('/kaggle/working/cub_embedding_model_standard_vit.keras')\n\n# Save the full model\nfull_model.save('/kaggle/working/cub_full_model_standard_vit.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T12:50:31.526570Z","iopub.execute_input":"2025-05-11T12:50:31.527124Z","iopub.status.idle":"2025-05-11T12:50:31.672064Z","shell.execute_reply.started":"2025-05-11T12:50:31.527103Z","shell.execute_reply":"2025-05-11T12:50:31.671311Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Load the embedding model\nimport tensorflow as tf\nembedding_model_loaded = tf.keras.models.load_model('/kaggle/working/cub_embedding_model_standard_vit.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T12:51:33.210532Z","iopub.execute_input":"2025-05-11T12:51:33.211178Z","iopub.status.idle":"2025-05-11T12:51:33.238609Z","shell.execute_reply.started":"2025-05-11T12:51:33.211154Z","shell.execute_reply":"2025-05-11T12:51:33.237552Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m             \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             return functional_from_config(\n\u001b[0m\u001b[1;32m    526\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mfunctional_from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"layers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             layer = serialization_lib.deserialize_keras_object(\n\u001b[0m\u001b[1;32m    462\u001b[0m                 \u001b[0mlayer_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     cls = _retrieve_class_or_fn(\n\u001b[0m\u001b[1;32m    695\u001b[0m         \u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36m_retrieve_class_or_fn\u001b[0;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m     raise TypeError(\n\u001b[0m\u001b[1;32m    813\u001b[0m         \u001b[0;34mf\"Could not locate {obj_type} '{name}'. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Could not locate class 'ViTCLSLayer'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': None, 'class_name': 'ViTCLSLayer', 'config': {'name': 'vit_cls_token', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'ViTCLSLayer', 'build_config': {'input_shape': [None, 224, 224, 3]}, 'name': 'vit_cls_token', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 224, 224, 3], 'dtype': 'float32', 'keras_history': ['input', 0, 0]}}], 'kwargs': {}}]}","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/4248768924.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the embedding model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0membedding_model_loaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/working/cub_embedding_model_standard_vit.keras'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_zip\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_keras_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         return saving_lib.load_model(\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    363\u001b[0m             )\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             return _load_model_from_fileobj(\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36m_load_model_from_fileobj\u001b[0;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mconfig_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         model = _model_from_config(\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0mconfig_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36m_model_from_config\u001b[0;34m(config_json, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;31m# Construct the model from the configuration file in the archive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mObjectSharingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         model = deserialize_keras_object(\n\u001b[0m\u001b[1;32m    432\u001b[0m             \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    721\u001b[0m                 \u001b[0;34mf\"{cls} could not be deserialized properly. Please\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0;34m\" ensure that components that are Python object\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: <class 'keras.src.models.functional.Functional'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras.src.models.functional', 'class_name': 'Functional', 'config': {'name': 'vit_embedding_model', 'trainable': True, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': [None, 224, 224, 3], 'dtype': 'float32', 'sparse': False, 'name': 'input'}, 'registered_name': None, 'name': 'input', 'inbound_nodes': []}, {'module': None, 'class_name': 'ViTCLSLayer', 'config': {'name': 'vit_cls_token', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'ViTCLSLayer', 'build_config': {'input_shape': [None, 224, 224, 3]}, 'name': 'vit_cls_token', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 224, 224, 3], 'dtype': 'float32', 'keras_history': ['input', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 136934670513168}, 'units': 1000, 'activation': 'silu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 384]}, 'name': 'dense_6', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 384], 'dtype': 'float32', 'keras_history': ['vit_cls_token', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 136934670513168}, 'units': 1024, 'activation': 'silu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': {'module': 'keras.regularizers', 'class_name': 'L2', 'config': {'l2': 0.05}, 'registered_name': None}, 'bias_regularizer': {'module': 'keras.regularizers', 'class_name': 'L2', 'config': {'l2': 0.01}, 'registered_name': None}, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 1000]}, 'name': 'dense_7', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 1000], 'dtype': 'float32', 'keras_history': ['dense_6', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 136934670513168}, 'rate': 0.2, 'seed': None, 'noise_shape': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 1024]}, 'name': 'dropout_3', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 1024], 'dtype': 'float32', 'keras_history': ['dense_7', 0, 0]}}], 'kwargs': {'training': False}}]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_8', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 136934670513168}, 'units': 512, 'activation': 'silu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': {'module': 'keras.regularizers', 'class_name': 'L2', 'config': {'l2': 0.05}, 'registered_name': None}, 'bias_regularizer': {'module': 'keras.regularizers', 'class_name': 'L2', 'config': {'l2': 0.01}, 'registered_name': None}, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 1024]}, 'name': 'dense_8', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 1024], 'dtype': 'float32', 'keras_history': ['dropout_3', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 136934670513168}, 'rate': 0.2, 'seed': None, 'noise_shape': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 512]}, 'name': 'dropout_4', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 512], 'dtype': 'float32', 'keras_history': ['dense_8', 0, 0]}}], 'kwargs': {'training': False}}]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 136934670513168}, 'units': 512, 'activation': 'silu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': {'module': 'keras.regularizers', 'class_name': 'L2', 'config': {'l2': 0.05}, 'registered_name': None}, 'bias_regularizer': {'module': 'keras.regularizers', 'class_name': 'L2', 'config': {'l2': 0.01}, 'registered_name': None}, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 512]}, 'name': 'dense_9', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 512], 'dtype': 'float32', 'keras_history': ['dropout_4', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 136934670513168}, 'rate': 0.2, 'seed': None, 'noise_shape': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 512]}, 'name': 'dropout_5', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 512], 'dtype': 'float32', 'keras_history': ['dense_9', 0, 0]}}], 'kwargs': {'training': False}}]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 136934670513168}, 'units': 1024, 'activation': 'silu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': {'module': 'keras.regularizers', 'class_name': 'L2', 'config': {'l2': 0.05}, 'registered_name': None}, 'bias_regularizer': {'module': 'keras.regularizers', 'class_name': 'L2', 'config': {'l2': 0.01}, 'registered_name': None}, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 512]}, 'name': 'dense_10', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 512], 'dtype': 'float32', 'keras_history': ['dropout_5', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_11', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 136934670513168}, 'units': 1000, 'activation': 'silu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 1024]}, 'name': 'dense_11', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 1024], 'dtype': 'float32', 'keras_history': ['dense_10', 0, 0]}}], 'kwargs': {}}]}], 'input_layers': [['input', 0, 0]], 'output_layers': [['dense_11', 0, 0]]}, 'registered_name': 'Functional', 'build_config': {'input_shape': None}}.\n\nException encountered: Could not locate class 'ViTCLSLayer'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': None, 'class_name': 'ViTCLSLayer', 'config': {'name': 'vit_cls_token', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'ViTCLSLayer', 'build_config': {'input_shape': [None, 224, 224, 3]}, 'name': 'vit_cls_token', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 224, 224, 3], 'dtype': 'float32', 'keras_history': ['input', 0, 0]}}], 'kwargs': {}}]}"],"ename":"TypeError","evalue":"<class 'keras.src.models.functional.Functional'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'keras.src.models.functional', 'class_name': 'Functional', 'config': {'name': 'vit_embedding_model', 'trainable': True, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': [None, 224, 224, 3], 'dtype': 'float32', 'sparse': False, 'name': 'input'}, 'registered_name': None, 'name': 'input', 'inbound_nodes': []}, {'module': None, 'class_name': 'ViTCLSLayer', 'config': {'name': 'vit_cls_token', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'ViTCLSLayer', 'build_config': {'input_shape': [None, 224, 224, 3]}, 'name': 'vit_cls_token', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 224, 224, 3], 'dtype': 'float32', 'keras_history': ['input', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 136934670513168}, 'units': 1000, 'activation': 'silu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 384]}, 'name': 'dense_6', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 384], 'dtype': 'float32', 'keras_history': ['vit_cls_token', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 136934670513168}, 'units': 1024, 'activation': 'silu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': {'module': 'keras.regularizers', 'class_name': 'L2', 'config': {'l2': 0.05}, 'registered_name': None}, 'bias_regularizer': {'module': 'keras.regularizers', 'class_name': 'L2', 'config': {'l2': 0.01}, 'registered_name': None}, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 1000]}, 'name': 'dense_7', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 1000], 'dtype': 'float32', 'keras_history': ['dense_6', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 136934670513168}, 'rate': 0.2, 'seed': None, 'noise_shape': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 1024]}, 'name': 'dropout_3', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 1024], 'dtype': 'float32', 'keras_history': ['dense_7', 0, 0]}}], 'kwargs': {'training': False}}]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_8', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 136934670513168}, 'units': 512, 'activation': 'silu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': {'module': 'keras.regularizers', 'class_name': 'L2', 'config': {'l2': 0.05}, 'registered_name': None}, 'bias_regularizer': {'module': 'keras.regularizers', 'class_name': 'L2', 'config': {'l2': 0.01}, 'registered_name': None}, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 1024]}, 'name': 'dense_8', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 1024], 'dtype': 'float32', 'keras_history': ['dropout_3', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 136934670513168}, 'rate': 0.2, 'seed': None, 'noise_shape': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 512]}, 'name': 'dropout_4', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 512], 'dtype': 'float32', 'keras_history': ['dense_8', 0, 0]}}], 'kwargs': {'training': False}}]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 136934670513168}, 'units': 512, 'activation': 'silu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': {'module': 'keras.regularizers', 'class_name': 'L2', 'config': {'l2': 0.05}, 'registered_name': None}, 'bias_regularizer': {'module': 'keras.regularizers', 'class_name': 'L2', 'config': {'l2': 0.01}, 'registered_name': None}, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 512]}, 'name': 'dense_9', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 512], 'dtype': 'float32', 'keras_history': ['dropout_4', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 136934670513168}, 'rate': 0.2, 'seed': None, 'noise_shape': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 512]}, 'name': 'dropout_5', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 512], 'dtype': 'float32', 'keras_history': ['dense_9', 0, 0]}}], 'kwargs': {'training': False}}]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 136934670513168}, 'units': 1024, 'activation': 'silu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': {'module': 'keras.regularizers', 'class_name': 'L2', 'config': {'l2': 0.05}, 'registered_name': None}, 'bias_regularizer': {'module': 'keras.regularizers', 'class_name': 'L2', 'config': {'l2': 0.01}, 'registered_name': None}, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 512]}, 'name': 'dense_10', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 512], 'dtype': 'float32', 'keras_history': ['dropout_5', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_11', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None, 'shared_object_id': 136934670513168}, 'units': 1000, 'activation': 'silu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 1024]}, 'name': 'dense_11', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 1024], 'dtype': 'float32', 'keras_history': ['dense_10', 0, 0]}}], 'kwargs': {}}]}], 'input_layers': [['input', 0, 0]], 'output_layers': [['dense_11', 0, 0]]}, 'registered_name': 'Functional', 'build_config': {'input_shape': None}}.\n\nException encountered: Could not locate class 'ViTCLSLayer'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': None, 'class_name': 'ViTCLSLayer', 'config': {'name': 'vit_cls_token', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'ViTCLSLayer', 'build_config': {'input_shape': [None, 224, 224, 3]}, 'name': 'vit_cls_token', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 224, 224, 3], 'dtype': 'float32', 'keras_history': ['input', 0, 0]}}], 'kwargs': {}}]}","output_type":"error"}],"execution_count":18},{"cell_type":"code","source":"from sklearn.metrics import normalized_mutual_info_score\nimport numpy as np\nfrom sklearn.cluster import KMeans\n\ndef evaluation(X, Y, Kset):\n    num = X.shape[0]\n    classN = np.max(Y) + 1\n    kmax = np.max(Kset)\n    recallK = np.zeros(len(Kset))\n    \n    # Compute NMI using KMeans clustering\n    kmeans = KMeans(n_clusters=classN).fit(X)\n    nmi = normalized_mutual_info_score(Y, kmeans.labels_, average_method='arithmetic')\n    \n    # Compute Recall@K\n    sim = X.dot(X.T)\n    minval = np.min(sim) - 1.\n    sim -= np.diag(np.diag(sim))\n    sim += np.diag(np.ones(num) * minval)\n    indices = np.argsort(-sim, axis=1)[:, :kmax]\n    YNN = Y[indices]\n    \n    for i in range(len(Kset)):\n        pos = 0.\n        for j in range(num):\n            if Y[j] in YNN[j, :Kset[i]]:\n                pos += 1.\n        recallK[i] = pos / num\n    \n    return nmi, recallK\n\ndef calculate_metrics(embedding_model, val_data, labels, k_values):\n    # Generate embeddings for the validation set\n    embeddings = embedding_model.predict(val_data)\n    \n    # Convert labels to the appropriate format\n    labels = np.argmax(labels, axis=1)  # Assuming labels are one-hot encoded\n    \n    # Calculate NMI and Recall@K\n    nmi_score, recall_scores = evaluation(embeddings, labels, k_values)\n    \n    return recall_scores, nmi_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T12:53:01.308777Z","iopub.execute_input":"2025-05-11T12:53:01.309360Z","iopub.status.idle":"2025-05-11T12:53:01.622189Z","shell.execute_reply.started":"2025-05-11T12:53:01.309337Z","shell.execute_reply":"2025-05-11T12:53:01.621569Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"k_values = [1, 2, 4, 8, 16, 32, 64, 128]\nrecall_scores_test, nmi_score_test = calculate_metrics(embedding_model, X_test, y_test, k_values)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T12:53:15.845312Z","iopub.execute_input":"2025-05-11T12:53:15.845584Z","iopub.status.idle":"2025-05-11T12:54:16.401768Z","shell.execute_reply.started":"2025-05-11T12:53:15.845565Z","shell.execute_reply":"2025-05-11T12:54:16.400884Z"}},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1746968005.512024     103 service.cc:148] XLA service 0x7c8708033650 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1746968005.512789     103 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1746968005.512810     103 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  3/145\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 95ms/step","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1746968007.688568     103 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 139ms/step\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"print(recall_scores_test, nmi_score_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T12:54:20.970058Z","iopub.execute_input":"2025-05-11T12:54:20.970369Z","iopub.status.idle":"2025-05-11T12:54:20.974812Z","shell.execute_reply.started":"2025-05-11T12:54:20.970345Z","shell.execute_reply":"2025-05-11T12:54:20.974155Z"}},"outputs":[{"name":"stdout","text":"[0.85738943 0.90226537 0.92729234 0.94886731 0.96591154 0.98360302\n 0.99007551 0.99395901] 0.9309972836880591\n","output_type":"stream"}],"execution_count":21}]}